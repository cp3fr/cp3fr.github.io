[{"authors":null,"categories":null,"content":"I am a postdoctoral researcher at the University of Zurich Robotics \u0026amp; Perception Group led by Prof. Davide Scaramuzza.\nMy research interest lie in the intersection of neuroscience, machine learning and robotics. I currently focus on visual-motor coordination and decision-making in first-person view drone racing.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am a postdoctoral researcher at the University of Zurich Robotics \u0026amp; Perception Group led by Prof. Davide Scaramuzza.\nMy research interest lie in the intersection of neuroscience, machine learning and robotics.","tags":null,"title":"Christian Pfeiffer","type":"authors"},{"authors":["Christian Pfeiffer","Davide Scaramuzza"],"categories":null,"content":"","date":1617235200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617235200,"objectID":"8789d256c8923ec80a74e1e4baffb7ae","permalink":"https://cp3fr.github.io/publication/pfeiffer-2021/","publishdate":"2021-04-07T09:46:13.659144Z","relpermalink":"/publication/pfeiffer-2021/","section":"publication","summary":"Humans race drones faster and more agile than algorithms, despite being limited to a fixed camera angle, body rate control, and response latencies in the order of hundreds of milliseconds. A better understanding of the ability of human pilots of selecting appropriate motor commands from highly dynamic visual information may provide key insights for solving current challenges in vision-based autonomous navigation. The aim of this study was to investigate the relationship between flight performance, control behavior, and eye movements of human pilots in a drone racing task. We collected a multimodal dataset from 21 experienced drone pilots using a highly realistic drone racing simulator, also used to recruit professional pilots. Our results showed task-specific improvements in drone racing performance over time. Gaze fixations not only tracked future waypoints but also anticipated the future flight path. Cross-correlation analysis showed a strong spatio-temporal relationship between eye movements, camera orienting behavior, and thrust vector control. These results highlight the importance of coordinated eye movements in human-piloted drone racing.","tags":["Aerial Systems: Perception and Autonomy","Automobiles","Drones","Eye-Tracking","Human Factors and Human-in-the-Loop","Logic gates","Perception-Action Coupling","Roads","Tracking","Vehicles","Vision-Based Navigation","Visualization"],"title":"Human-Piloted Drone Racing: Visual Processing and Control","type":"publication"},{"authors":["Christian Pfeiffer","Nora Hollenstein","Ce Zhang","Nicolas Langer"],"categories":null,"content":"","date":1598918400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598918400,"objectID":"512ce24826b9ca5d073757240eebaa14","permalink":"https://cp3fr.github.io/publication/pfeiffer-2020/","publishdate":"2021-04-07T09:46:13.659563Z","relpermalink":"/publication/pfeiffer-2020/","section":"publication","summary":"When we read, our eyes move through the text in a series of fixations and high-velocity saccades to extract visual information. This process allows the brain to obtain meaning, e.g., about sentiment, or the emotional valence, expressed in the written text. How exactly the brain extracts the sentiment of single words during naturalistic reading is largely unknown. This is due to the challenges of naturalistic imaging, which has previously led researchers to employ highly controlled, timed word-by-word presentations of custom reading materials that lack ecological validity. Here, we aimed to assess the electrical neural correlates of word sentiment processing during naturalistic reading of English sentences. We used a publicly available dataset of simultaneous electroencephalography (EEG), eye-tracking recordings, and word-level semantic annotations from 7129 words in 400 sentences (Zurich Cognitive Language Processing Corpus; Hollenstein et al., 2018). We computed fixation-related potentials (FRPs), which are evoked electrical responses time-locked to the onset of fixations. A general linear mixed model analysis of FRPs cleaned from visual- and motor-evoked activity showed a topographical difference between the positive and negative sentiment condition in the 224–304 ​ms interval after fixation onset in left-central and right-posterior electrode clusters. An additional analysis that included word-, phrase-, and sentence-level sentiment predictors showed the same FRP differences for the word-level sentiment, but no additional FRP differences for phrase- and sentence-level sentiment. Furthermore, decoding analysis that classified word sentiment (positive or negative) from sentiment-matched 40-trial average FRPs showed a 0.60 average accuracy (95% confidence interval: [0.58, 0.61]). Control analyses ruled out that these results were based on differences in eye movements or linguistic features other than word sentiment. Our results extend previous research by showing that the emotional valence of lexico-semantic stimuli evoke a fast electrical neural response upon word fixation during naturalistic reading. These results provide an important step to identify the neural processes of lexico-semantic processing in ecologically valid conditions and can serve to improve computer algorithms for natural language processing.","tags":null,"title":"Neural dynamics of sentiment processing during naturalistic sentence reading","type":"publication"},{"authors":["Christian Pfeiffer","Jean‐Paul Noel","Andrea Serino","Olaf Blanke"],"categories":null,"content":"","date":1522540800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1522540800,"objectID":"f8262663d72ba0d67439ee7c601f4768","permalink":"https://cp3fr.github.io/publication/pfeiffer-2018/","publishdate":"2021-04-07T09:46:13.659884Z","relpermalink":"/publication/pfeiffer-2018/","section":"publication","summary":"Human–environment interactions are mediated through the body and occur within the peripersonal space (PPS), the space immediately adjacent to and surrounding the body. The PPS is taken to be a critical interface between the body and the environment, and indeed, body-part specific PPS remapping has been shown to depend on body-part utilization, such as upper limb movements in otherwise static observers. How vestibular signals induced by whole-body movement contribute to PPS representation is less well understood. In a series of experiments, we mapped the spatial extension of the PPS around the head while participants were submitted to passive whole-body rotations inducing vestibular stimulation. Forty-six participants, in three experiments, executed a tactile detection reaction time task while task-irrelevant auditory stimuli approached them. The maximal distance at which the auditory stimulus facilitated tactile reaction time was taken as a proxy for the boundary of peri-head space. The present results indicate two distinct vestibular effects. First, vestibular stimulation speeded tactile detection indicating a vestibular facilitation of somatosensory processing. Second, vestibular stimulation modulated audio-tactile interaction of peri-head space in a rotation direction-specific manner. Congruent but not incongruent audio-vestibular motion stimuli expanded the PPS boundary further away from the body as compared to no rotation. These results show that vestibular inputs dynamically update the multisensory delineation of PPS and far space, which may serve to maintain accurate tracking of objects close to the body and to update spatial self-representations.","tags":["humans","multisensory processing","peripersonal space","self-motion","vestibular system"],"title":"Vestibular modulation of peripersonal space boundaries","type":"publication"},{"authors":["Christian Pfeiffer","Marzia De Lucia"],"categories":null,"content":"","date":1512086400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1512086400,"objectID":"622ca9426262dbdf74447a4888d84309","permalink":"https://cp3fr.github.io/publication/pfeiffer-2017/","publishdate":"2021-04-07T09:46:13.660332Z","relpermalink":"/publication/pfeiffer-2017/","section":"publication","summary":"Successful prediction of future events depends on the brain's capacity to extract temporal regularities from sensory inputs. Neuroimaging studies mainly investigated regularity processing for exteroceptive sensory inputs (i.e. from outside the body). Here we investigated whether interoceptive signals (i.e. from inside the body) can mediate auditory regularity processing. Human participants passively listened to sound sequences presented in synchrony or asynchrony to their heartbeat while concomitant electroencephalography was recorded. We hypothesized that the cardio-audio synchronicity would induce a brain expectation of future sounds. Electrical neuroimaging analysis revealed a surprise response at 158-270 ms upon omission of the expected sounds in the synchronous condition only. Control analyses ruled out that this effect was trivially based on expectation from the auditory temporal structure or on differences in heartbeat physiological signals. Implicit neural monitoring of temporal regularities across interoceptive and exteroceptive signals drives prediction of future events in auditory sequences.","tags":null,"title":"Cardio-audio synchronization drives neural surprise response","type":"publication"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"e8f8d235e8e7f2efd912bfe865363fc3","permalink":"https://cp3fr.github.io/project/example/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/example/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Example Project","type":"project"},{"authors":["Christian Pfeiffer","Michiel van Elk","Fosco Bernasconi","Olaf Blanke"],"categories":null,"content":"","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"cdea5f3d93d49a53400a5a8075d3efba","permalink":"https://cp3fr.github.io/publication/pfeiffer-2016/","publishdate":"2021-04-07T09:46:13.660765Z","relpermalink":"/publication/pfeiffer-2016/","section":"publication","summary":"In non-human primates several brain areas contain neurons that respond to both vestibular and somatosensory stimulation. In humans, vestibular stimulation activates several somatosensory brain regions and improves tactile perception. However, less is known about the spatio-temporal dynamics of such vestibular-somatosensory interactions in the human brain. To address this issue, we recorded high-density electroencephalography during left median nerve electrical stimulation to obtain Somatosensory Evoked Potentials (SEPs). We analyzed SEPs during vestibular activation following sudden decelerations from constant-velocity (90°/s and 60°/s) earth-vertical axis yaw rotations and SEPs during a non-vestibular control period. SEP analysis revealed two distinct temporal effects of vestibular activation: An early effect (28-32 ms post-stimulus) characterized by vestibular suppression of SEP response strength that depended on rotation velocity and a later effect (97-112 ms post-stimulus) characterized by vestibular modulation of SEP topographical pattern that was rotation velocity-independent. Source estimation localized these vestibular effects, during both time periods, to activation differences in a distributed cortical network including the right postcentral gyrus, right insula, left precuneus, and bilateral secondary somatosensory cortex. These results suggest that vestibular-somatosensory interactions in humans depend on processing in specific time periods in somatosensory and vestibular cortical regions.","tags":["EEG","Electrical neuroimaging","Multisensory processing","Somatosensory cortex","Somatosensory evoked potentials","Vestibular system"],"title":"Distinct vestibular effects on early and late somatosensory cortical processing in humans","type":"publication"},{"authors":["Christian Pfeiffer","Andrea Serino","Olaf Blanke"],"categories":null,"content":"","date":1396310400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1396310400,"objectID":"960bae82e7fc2ac09f2f4b175496209c","permalink":"https://cp3fr.github.io/publication/pfeiffer-2014/","publishdate":"2021-04-07T09:46:13.661366Z","relpermalink":"/publication/pfeiffer-2014/","section":"publication","summary":"Self-consciousness is the remarkable human experience of being a subject: the \"I\". Self-consciousness is typically bound to a body, and particularly to the spatial dimensions of the body, as well as to its location and displacement in the gravitational field. Because the vestibular system encodes head position and movement in three-dimensional space, vestibular cortical processing likely contributes to spatial aspects of bodily self-consciousness. We review here recent data showing vestibular effects on first-person perspective (the feeling from where \"I\" experience the world) and self-location (the feeling where \"I\" am located in space). We compare these findings to data showing vestibular effects on mental spatial transformation, self-motion perception, and body representation showing vestibular contributions to various spatial representations of the body with respect to the external world. Finally, we discuss the role for four posterior brain regions that process vestibular and other multisensory signals to encode spatial aspects of bodily self-consciousness: temporoparietal junction, parietoinsular vestibular cortex, ventral intraparietal region, and medial superior temporal region. We propose that vestibular processing in these cortical regions is critical in linking multisensory signals from the body (personal and peripersonal space) with external (extrapersonal) space. Therefore, the vestibular system plays a critical role for neural representations of spatial aspects of bodily self-consciousness. © 2014 Pfeiffer, Serino and Blanke.","tags":["Bodily self-consciousness","Body representation","First-person perspective","Mental spatial transformation","Multisensory integration","Self-location","Self-motion","Vestibular cortex"],"title":"The vestibular system: a spatial reference for bodily self-consciousness","type":"publication"},{"authors":["Christian Pfeiffer","Christophe Lopez","Valentin Schmutz","Julio Angel Duenas","Roberto Martuzzi","Olaf Blanke"],"categories":null,"content":"","date":1364774400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1364774400,"objectID":"d0281fdaa557b67117ff275952c2d03d","permalink":"https://cp3fr.github.io/publication/pfeiffer-2013/","publishdate":"2021-04-07T09:46:13.662017Z","relpermalink":"/publication/pfeiffer-2013/","section":"publication","summary":"In three experiments we investigated the effects of visuo-tactile and visuo-vestibular conflict about the direction of gravity on three aspects of bodily self-consciousness: self-identification, self-location, and the experienced direction of the first-person perspective. Robotic visuo-tactile stimulation was administered to 78 participants in three experiments. Additionally, we presented participants with a virtual body as seen from an elevated and downward-directed perspective while they were lying supine and were therefore receiving vestibular and postural cues about an upward-directed perspective. Under these conditions, we studied the effects of different degrees of visuo-vestibular conflict, repeated measurements during illusion induction, and the relationship to a classical measure of visuo-vestibular integration. Extending earlier findings on experimentally induced changes in bodily self-consciousness, we show that self-identification does not depend on the experienced direction of the first-person perspective, whereas self-location does. Changes in bodily self-consciousness depend on visual gravitational signals. Individual differences in the experienced direction of first-person perspective correlated with individual differences in visuo-vestibular integration. Our data reveal important contributions of visuo-vestibular gravitational cues to bodily self-consciousness. In particular we show that the experienced direction of the first-person perspective depends on the integration of visual, vestibular, and tactile signals, as well as on individual differences in idiosyncratic visuo-vestibular strategies. © 2013 Pfeiffer et al.","tags":null,"title":"Multisensory Origin of the Subjective First-Person Perspective: Visual, Tactile, and Vestibular Mechanisms","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://cp3fr.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]