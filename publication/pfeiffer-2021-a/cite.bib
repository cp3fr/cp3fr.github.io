@article{Pfeiffer2021a,
 abstract = {Humans race drones faster and more agile than algorithms, despite being limited to a fixed camera angle, body rate control, and response latencies in the order of hundreds of milliseconds. A better understanding of the ability of human pilots of selecting appropriate motor commands from highly dynamic visual information may provide key insights for solving current challenges in vision-based autonomous navigation. The aim of this study was to investigate the relationship between flight performance, control behavior, and eye movements of human pilots in a drone racing task. We collected a multimodal dataset from 21 experienced drone pilots using a highly realistic drone racing simulator, also used to recruit professional pilots. Our results showed task-specific improvements in drone racing performance over time. Gaze fixations not only tracked future waypoints but also anticipated the future flight path. Cross-correlation analysis showed a strong spatio-temporal relationship between eye movements, camera orienting behavior, and thrust vector control. These results highlight the importance of coordinated eye movements in human-piloted drone racing.},
 archiveprefix = {arXiv},
 arxivid = {2103.04672},
 author = {Pfeiffer, Christian and Scaramuzza, Davide},
 doi = {10.1109/LRA.2021.3064282},
 eprint = {2103.04672},
 file = {:home/cp3fr/Mendeley/library/Pfeiffer, Scaramuzza_2021_Human-Piloted Drone Racing Visual Processing and Control(2).pdf:pdf},
 issn = {2377-3766},
 journal = {IEEE Robotics and Automation Letters},
 keywords = {Aerial Systems: Perception and Autonomy,Automobiles,Drones,Eye-Tracking,Human Factors and Human-in-the-Loop,Logic gates,Perception-Action Coupling,Roads,Tracking,Vehicles,Vision-Based Navigation,Visualization},
 month = {apr},
 number = {2},
 pages = {3467--3474},
 title = {Human-Piloted Drone Racing: Visual Processing and Control},
 url = {https://ieeexplore.ieee.org/document/9372809/},
 volume = {6},
 year = {2021}
}

